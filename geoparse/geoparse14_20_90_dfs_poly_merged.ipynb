{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77feefce-9f81-45f5-bc5d-4a3b4835c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Environment Setup\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, box, mapping, shape, MultiPolygon\n",
    "from shapely.strtree import STRtree\n",
    "from shapely.ops import unary_union\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "from shapely.geometry import box\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm  # Better for Jupyter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e008b231-71c8-49f3-b86c-bd32a8be1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iou = 20% 0.2; confidence = 0.9\n",
    "\n",
    "# --- Configure Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# --- Load GeoJSON ---\n",
    "def load_geojson(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        logging.info(f\"Successfully loaded GeoJSON: {file_path}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading GeoJSON: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Geometry Helpers ---\n",
    "def calculate_overlap(p1, p2):\n",
    "    if not p1.intersects(p2):\n",
    "        return 0\n",
    "    inter = p1.intersection(p2).area\n",
    "    union = p1.area + p2.area - inter\n",
    "    return inter / union if union > 0 else 0\n",
    "\n",
    "# --- Extract polygons from features (handle Polygon and MultiPolygon) ---\n",
    "def extract_polygons(features, conf_thresh=0.9): # CHANGED TO 0.9\n",
    "    valid_polys = []\n",
    "    skipped = []\n",
    "\n",
    "    for f in features:\n",
    "        props = f.get(\"properties\", {})\n",
    "        cls_name = props.get(\"classification\", {}).get(\"name\", \"\").lower()\n",
    "        confidence = props.get(\"confidence\", 1)\n",
    "        if cls_name != \"eos\" or confidence < conf_thresh:\n",
    "            skipped.append(f)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            geom = shape(f[\"geometry\"])\n",
    "            if isinstance(geom, Polygon):\n",
    "                if geom.is_valid:\n",
    "                    valid_polys.append(geom)\n",
    "                else:\n",
    "                    skipped.append(f)\n",
    "            elif isinstance(geom, MultiPolygon):\n",
    "                valid_polys.extend([g for g in geom.geoms if g.is_valid])\n",
    "            else:\n",
    "                skipped.append(f)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Invalid geometry skipped: {e}\")\n",
    "            skipped.append(f)\n",
    "\n",
    "    logging.info(f\"Extracted {len(valid_polys)} valid eos polygons, skipped {len(skipped)} features.\")\n",
    "    return valid_polys, skipped\n",
    "\n",
    "# --- Cluster eos polygons by DFS using IoU threshold ---\n",
    "def cluster_eos(polygons, iou_thresh=0.2): # # CHANGED TO 0.2\n",
    "    if not polygons:\n",
    "        return []\n",
    "\n",
    "    n = len(polygons)\n",
    "    adjacency = [[] for _ in range(n)]\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if calculate_overlap(polygons[i], polygons[j]) > iou_thresh:\n",
    "                adjacency[i].append(j)\n",
    "                adjacency[j].append(i)\n",
    "\n",
    "    visited = set()\n",
    "    clusters = []\n",
    "\n",
    "    def dfs(node):\n",
    "        stack = [node]\n",
    "        cluster = []\n",
    "        while stack:\n",
    "            curr = stack.pop()\n",
    "            if curr not in visited:\n",
    "                visited.add(curr)\n",
    "                cluster.append(curr)\n",
    "                stack.extend([nbr for nbr in adjacency[curr] if nbr not in visited])\n",
    "        return cluster\n",
    "\n",
    "    for i in range(n):\n",
    "        if i not in visited:\n",
    "            clusters.append(dfs(i))\n",
    "\n",
    "    merged_polys = []\n",
    "    for c in clusters:\n",
    "        merged = unary_union([polygons[i] for i in c])\n",
    "        if isinstance(merged, MultiPolygon):\n",
    "            merged = max(merged.geoms, key=lambda p: p.area)\n",
    "        merged_polys.append(merged)\n",
    "\n",
    "    logging.info(f\"Formed {len(clusters)} clusters from {n} polygons.\")\n",
    "    return merged_polys\n",
    "\n",
    "# --- Analyze GeoJSON to find peak HPF and eos clusters ---\n",
    "def analyze_geojson(data, hpf_size, iou_thresh=0.2, conf_thresh=0.9): # CHANGED TO 0.2 and 0.9 \n",
    "    features = data['features']\n",
    "    all_polys, skipped = extract_polygons(features, conf_thresh=conf_thresh)\n",
    "\n",
    "    if not all_polys:\n",
    "        raise ValueError(\"No valid eos polygons found in the GeoJSON.\")\n",
    "\n",
    "    # Calculate bounding box extents\n",
    "    all_coords = [pt for poly in all_polys for pt in poly.exterior.coords]\n",
    "    min_x, max_x = int(min(p[0] for p in all_coords)), int(max(p[0] for p in all_coords))\n",
    "    min_y, max_y = int(min(p[1] for p in all_coords)), int(max(p[1] for p in all_coords))\n",
    "\n",
    "    max_eos = 0\n",
    "    hpf_count = 0\n",
    "    peak_box, peak_merged_polys = None, []\n",
    "\n",
    "    logging.info(\"Scanning HPFs for peak eos count...\")\n",
    "    for x in tqdm(range(min_x, max_x, hpf_size), desc=\"HPF cols\"):\n",
    "        for y in range(min_y, max_y, hpf_size):\n",
    "            hpf = box(x, y, x + hpf_size, y + hpf_size)\n",
    "            # Polygons that intersect HPF\n",
    "            local_polys = [p for p in all_polys if hpf.intersects(p)]\n",
    "            merged_polys = cluster_eos(local_polys, iou_thresh=iou_thresh)\n",
    "            eos_count = len(merged_polys)\n",
    "            if eos_count > max_eos:\n",
    "                max_eos = eos_count\n",
    "                peak_box = hpf\n",
    "                peak_merged_polys = merged_polys\n",
    "            hpf_count += 1\n",
    "\n",
    "    logging.info(f\"Total HPFs analyzed: {hpf_count}\")\n",
    "    logging.info(f\"Peak eos count in one HPF (clustered): {max_eos}\")\n",
    "\n",
    "    return hpf_count, max_eos, peak_box, peak_merged_polys, min_x, min_y, max_x, max_y\n",
    "\n",
    "# --- Save peak HPF and merged eos polygons as GeoJSON ---\n",
    "def save_peak_to_geojson(hpf_box, merged_polys, out_path):\n",
    "    geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": []\n",
    "    }\n",
    "    geojson[\"features\"].append({\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": mapping(hpf_box),\n",
    "        \"properties\": {\"name\": \"Peak HPF\"}\n",
    "    })\n",
    "\n",
    "    for i, poly in enumerate(merged_polys):\n",
    "        geojson[\"features\"].append({\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": mapping(poly),\n",
    "            \"properties\": {\"id\": i, \"name\": \"\"}\n",
    "        })\n",
    "\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(geojson, f, indent=2)\n",
    "    logging.info(f\"Saved merged eos GeoJSON to {out_path}\")\n",
    "\n",
    "# --- Generate heatmap of clustered eos counts per HPF ---\n",
    "def generate_heatmap_clustered(data, hpf_size, iou_thresh=0.2, conf_thresh=0.9): # CHANGED TO 0.2 and 0.9\n",
    "    features = data['features']\n",
    "    all_polys, _ = extract_polygons(features, conf_thresh=conf_thresh)\n",
    "\n",
    "    if not all_polys:\n",
    "        logging.error(\"No valid polygons for heatmap generation.\")\n",
    "        return\n",
    "\n",
    "    all_coords = [pt for poly in all_polys for pt in poly.exterior.coords]\n",
    "    min_x, max_x = int(min(p[0] for p in all_coords)), int(max(p[0] for p in all_coords))\n",
    "    min_y, max_y = int(min(p[1] for p in all_coords)), int(max(p[1] for p in all_coords))\n",
    "\n",
    "    cols = (max_x - min_x) // hpf_size + 1\n",
    "    rows = (max_y - min_y) // hpf_size + 1\n",
    "    heatmap = np.zeros((rows, cols))\n",
    "\n",
    "    logging.info(\"Generating heatmap from clustered eos counts...\")\n",
    "    for x_idx, x in enumerate(tqdm(range(min_x, max_x, hpf_size), desc=\"Heatmap cols\")):\n",
    "        for y_idx, y in enumerate(range(min_y, max_y, hpf_size)):\n",
    "            hpf = box(x, y, x + hpf_size, y + hpf_size)\n",
    "            local_polys = [p for p in all_polys if hpf.intersects(p)]\n",
    "            merged_polys = cluster_eos(local_polys, iou_thresh=iou_thresh)\n",
    "            heatmap[y_idx, x_idx] = len(merged_polys)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(heatmap, cmap='hot', interpolation='nearest', origin='upper')\n",
    "    plt.colorbar(label='Eosinophil Count per HPF')\n",
    "    plt.title('Eosinophil Density Heatmap (Clustered)')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9bb159-df6a-41c8-9a36-99645a8513c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '1007401_detections_merged.geojson'\n",
    "    output_geojson = '1007401_peak_hpf_output14_20_90_dfs_poly_merged.geojson'\n",
    "    hpf_size = 2144  # 548μm @ 0.2555 μm/pixel\n",
    "\n",
    "    geojson = load_geojson(file_path)\n",
    "    if geojson:\n",
    "        hpf_total, peak_eos, peak_box, peak_merged_polys, min_x, min_y, max_x, max_y = analyze_geojson(\n",
    "            geojson, hpf_size, iou_thresh=0.2, conf_thresh=0.9) # CHANGED TO 0.2 and 0.9\n",
    "\n",
    "        # Plot peak HPF with merged eos polygons\n",
    "        import matplotlib.patches as patches\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        x, y = peak_box.exterior.xy\n",
    "        ax.plot(x, y, color='red', linewidth=2, label='Peak HPF')\n",
    "\n",
    "        for poly in peak_merged_polys:\n",
    "            x, y = poly.exterior.xy\n",
    "            ax.fill(x, y, color='blue', alpha=0.5)\n",
    "\n",
    "        ax.set_title(\"Peak HPF with Merged Eosinophils\")\n",
    "        ax.set_aspect('equal')\n",
    "        ax.legend()\n",
    "        ax.invert_xaxis()  # Flip 180°\n",
    "        ax.invert_yaxis()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        save_peak_to_geojson(peak_box, peak_merged_polys, output_geojson)\n",
    "        generate_heatmap_clustered(geojson, hpf_size, iou_thresh=0.2, conf_thresh=0.9) # CHANGED TO 0.2 and 0.9\n",
    "    else:\n",
    "        logging.error(\"GeoJSON load failed. Terminating.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3900c-8966-401f-9aae-5c3593bbaeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
